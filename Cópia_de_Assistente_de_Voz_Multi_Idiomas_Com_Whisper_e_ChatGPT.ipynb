{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "xVJe979lA_8D"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolinacastilhos/Whisper_Python/blob/main/C%C3%B3pia_de_Assistente_de_Voz_Multi_Idiomas_Com_Whisper_e_ChatGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "language = 'pt' #podemos modificar a l√≠ngua, como 'en' para ingl√™s"
      ],
      "metadata": {
        "id": "nvvYFFNaf12H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Grava√ß√£o de √Åudio Com Python (e Uma Pitada de JavaScript) üé§"
      ],
      "metadata": {
        "id": "xVJe979lA_8D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQj2WnrRAoXR"
      },
      "outputs": [],
      "source": [
        "# Refer√™ncia: https://gist.github.com/korakot/c21c3476c024ad6d56d5f48b0bca92be\n",
        "\n",
        "from IPython.display import Audio, display, Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "# C√≥digo JavaScript para gravar √°udio do usu√°rio usando a \"MediaStream Recording API\"\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=5):\n",
        "  # Executa o c√≥digo JavaScript para gravar o √°udio\n",
        "  display(Javascript(RECORD))\n",
        "  # Recebe o √°udio gravado como resultado do JavaScript\n",
        "  js_result = output.eval_js('record(%s)' % (sec * 1000))\n",
        "   # Decodifica o √°udio em base64\n",
        "  audio = b64decode(js_result.split(',')[1]) #por conven√ß√£o o base64 √© o segundo elemento, por isso pega o √≠ndice [1]\n",
        "  # Salva o √°udio em um arquivo\n",
        "  file_name = 'request_audio.wav'\n",
        "  with open(file_name, 'wb') as f: #wb √© binaria\n",
        "    f.write(audio)\n",
        "  # Retorna o caminho do arquivo de √°udio (pasta padr√£o do Google Colab)\n",
        "  return f'/content/{file_name}' #f para formatar \n",
        "\n",
        "# Grava o √°udio do usu√°rio por um tempo determinado (padr√£o 5 segundos)\n",
        "print('Ouvindo...\\n')\n",
        "record_file = record()\n",
        "\n",
        "# Exibe o √°udio gravado - exibe o display de audio na tela \n",
        "display(Audio(record_file, autoplay=False)) #passar para true para come√ßar diretamente"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Reconhecimento de Fala com Whisper (OpenAI) üß†"
      ],
      "metadata": {
        "id": "YVtxLeSEGEqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0L7dwnuGMSj",
        "outputId": "9ba90534-afc5-4a19-e15e-671a6d68abba",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Selecione o modelo do Whisper que melhor atenda √†s suas necessidades:\n",
        "# https://github.com/openai/whisper#available-models-and-languages\n",
        "model = whisper.load_model(\"small\") #tem tbm os modelos tiny, base, medium e large. O small vai atender o requerido neste projeto.\n",
        "\n",
        "# Transcreve o audio gravado anteriormente.\n",
        "result = model.transcribe(record_file, fp16=False, language=language)\n",
        "transcription = result[\"text\"]\n",
        "print(transcription)"
      ],
      "metadata": {
        "id": "H18caD49dzQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Integra√ß√£o com a API do ChatGPT üí¨"
      ],
      "metadata": {
        "id": "TalupqHJRxir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "y_GodW9JR3R-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff21cbed-4576-44bf-fcb3-9672ca9d9db1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Documenta√ß√£o Oficial da API OpenAI: https://platform.openai.com/docs/api-reference/introduction\n",
        "# Informa√ß√µes sobre o Per√≠odo Gratuito: https://help.openai.com/en/articles/4936830\n",
        "\n",
        "# Para gerar uma API Key:\n",
        "# 1. Crie uma conta na OpenAI\n",
        "# 2. Acesse a se√ß√£o \"API Keys\"\n",
        "# 3. Clique em \"Create API Key\"\n",
        "# Link direto: https://platform.openai.com/account/api-keys\n",
        "\n",
        "# Substitua o texto \"TODO\" por sua API Key da OpenAI, ela ser√° salva como uma vari√°vel de ambiente.\n",
        "os.environ['OPENAI_API_KEY'] = 'TODO'"
      ],
      "metadata": {
        "id": "YfQYt9oUhL8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Configura a chave de API da OpenAI usando a vari√°vel de ambiente 'OPENAI_API_KEY'\n",
        "openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
        "\n",
        "# Envia uma requisi√ß√£o √† API do ChatCompletion usando o modelo GPT-3.5 Turbo\n",
        "# Lembrando que, a vari√°vel 'transcription' cont√©m a transcri√ß√£o do nosso √°udio.\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[ { \"role\": \"user\", \"content\": transcription } ]\n",
        ")\n",
        "\n",
        "# Obt√©m a resposta gerada pelo ChatGPT\n",
        "chatgpt_response = response.choices[0].message.content #teoricamente, a op√ß√£o de resposta do √≠ndice 0 √© a mais assertiva, por isso escolhemos ela\n",
        "print(chatgpt_response)"
      ],
      "metadata": {
        "id": "7wt7K280SSNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Sintetizando a Resposta do ChatGPT Como Voz (gTTS) üîä"
      ],
      "metadata": {
        "id": "w3mRPF-Ka-et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS"
      ],
      "metadata": {
        "id": "ztyl4KSGbP5E",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4daf6a7-44e7-4318-f392-351ca5c8a59d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.3.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.27.1)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (1.26.15)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import  gTTS\n",
        "\n",
        "# Cria um objeto gTTS com a resposta gerada pelo ChatGPT e a l√≠ngua que ser√° sintetizada em voz (vari√°vel \"language\").\n",
        "gtts_object = gTTS(text=chatgpt_response, lang=language, slow=False) #false no slow para que a voz do google fale de maneira mais natural\n",
        "\n",
        "# Salva o √°udio da resposta no arquivo especificado (pasta padr√£o do Google Colab)\n",
        "response_audio = \"/content/response_audio.wav\"\n",
        "gtts_object.save(response_audio)\n",
        "\n",
        "# Reproduz o √°udio da resposta salvo no arquivo\n",
        "display(Audio(response_audio, autoplay=True))"
      ],
      "metadata": {
        "id": "bAPhZQChbjfb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}